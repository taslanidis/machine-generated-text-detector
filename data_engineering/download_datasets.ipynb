{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-v0.3')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-UTF-8 characters (weird UTF-16 symbols)\n",
    "    clean_text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Remove special characters except letters, digits, spaces, and punctuation marks (.,!?;:)\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', '', clean_text)\n",
    "    \n",
    "    return clean_text.strip()\n",
    "\n",
    "\n",
    "def split_text(human_text, prompt_length, answer_length):\n",
    "\n",
    "    tokens = tokenizer(clean_text(human_text), return_tensors='pt', padding=True, truncation=True)\n",
    "    prompt = tokens['input_ids'].squeeze(0)[:prompt_length]\n",
    "    answer = tokens['input_ids'].squeeze(0)[prompt_length:prompt_length + answer_length]\n",
    "\n",
    "    prompt = tokenizer.decode(prompt)\n",
    "    answer = tokenizer.decode(answer)\n",
    "    \n",
    "    return prompt, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Data\n",
    "1. Squad\n",
    "2. Wikitext\n",
    "\n",
    "### Methodology\n",
    "\n",
    "Both datasets contain human written text. We will use this text, to prompt an LLM and let it generate few sentences to complete the text.\n",
    "\n",
    "As mentioned in bibliography, we will use `PRIME` tokens from the human text, and let it generate.\n",
    "\n",
    "Thus, we will have two samples starting from the same `PRIME` tokens:\n",
    "1. Human written - positive sample\n",
    "2. Machine generated - negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_fn(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    text = tokens['input_ids'].squeeze(0)\n",
    "    output = len(text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is 18891\n",
      "The number of validation samples is 2067\n"
     ]
    }
   ],
   "source": [
    "# loading squad\n",
    "squad_ds = load_dataset(\"rajpurkar/squad\")\n",
    "\n",
    "# Get dataset split and keep only the context\n",
    "train_squad = squad_ds['train'].to_pandas()[['context']]\n",
    "train_squad = train_squad.drop_duplicates(subset='context')\n",
    "print(f'The number of training samples is {len(train_squad)}')\n",
    "\n",
    "# Get dataset split and keep only the context\n",
    "val_squad = squad_ds['validation'].to_pandas()[['context']]\n",
    "val_squad = val_squad.drop_duplicates(subset='context')\n",
    "print(f'The number of validation samples is {len(val_squad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading wiki\n",
    "wiki_ds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-v1\")\n",
    "\n",
    "# getting dataset splits\n",
    "train_wiki = wiki_ds['train'].to_pandas()\n",
    "val_wiki = wiki_ds['validation'].to_pandas()\n",
    "test_wiki = wiki_ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# count tokens for our dfs\n",
    "\n",
    "# wikitext\n",
    "train_wiki['word_count'] = train_wiki['text'].apply(word_count_fn)\n",
    "val_wiki['word_count'] = val_wiki['text'].apply(word_count_fn)\n",
    "test_wiki['word_count'] = test_wiki['text'].apply(word_count_fn)\n",
    "\n",
    "# squad\n",
    "train_squad['word_count'] = train_squad['context'].apply(word_count_fn)\n",
    "val_squad['word_count'] = val_squad['context'].apply(word_count_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.801350e+06\n",
      "mean     7.563011e+01\n",
      "std      1.026569e+02\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.300000e+01\n",
      "75%      1.380000e+02\n",
      "max      1.781000e+03\n",
      "Name: word_count, dtype: float64\n",
      "count    3760.000000\n",
      "mean       76.341489\n",
      "std        99.312526\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%        14.000000\n",
      "75%       141.000000\n",
      "max       538.000000\n",
      "Name: word_count, dtype: float64\n",
      "count    4358.000000\n",
      "mean       74.891923\n",
      "std       100.971810\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%        13.000000\n",
      "75%       132.000000\n",
      "max       600.000000\n",
      "Name: word_count, dtype: float64\n",
      "count    18891.000000\n",
      "mean       176.584723\n",
      "std         76.554855\n",
      "min         27.000000\n",
      "25%        129.000000\n",
      "50%        163.000000\n",
      "75%        212.000000\n",
      "max       1053.000000\n",
      "Name: word_count, dtype: float64\n",
      "count    2067.000000\n",
      "mean      183.435897\n",
      "std        80.565770\n",
      "min        31.000000\n",
      "25%       134.000000\n",
      "50%       168.000000\n",
      "75%       216.000000\n",
      "max       839.000000\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#some statistics\n",
    "print(train_wiki['word_count'].describe())\n",
    "print(val_wiki['word_count'].describe())\n",
    "print(test_wiki['word_count'].describe())\n",
    "\n",
    "print(train_squad['word_count'].describe())\n",
    "print(val_squad['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep above one threshold\n",
    "prompt_length: int = 20\n",
    "answer_length: int = 140\n",
    "\n",
    "low_thres: int = prompt_length + answer_length\n",
    "high_thres: int = 1000\n",
    "\n",
    "train_wiki = train_wiki[(train_wiki['word_count']>low_thres) & (train_wiki['word_count']<high_thres)]\n",
    "val_wiki = val_wiki[(val_wiki['word_count']>low_thres) & (val_wiki['word_count']<high_thres)]\n",
    "test_wiki = test_wiki[(test_wiki['word_count']>low_thres) & (test_wiki['word_count']<high_thres)]\n",
    "train_squad = train_squad[(train_squad['word_count']>low_thres) & (train_squad['word_count']<high_thres)]\n",
    "val_squad = val_squad[(val_squad['word_count']>low_thres) & (val_squad['word_count']<high_thres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8751\n",
      "1143\n",
      "973\n"
     ]
    }
   ],
   "source": [
    "#transformations os squad\n",
    "\n",
    "train_squad, test_squad = train_test_split(train_squad, test_size=0.1)\n",
    "\n",
    "print(len(train_squad))\n",
    "print(len(val_squad))\n",
    "print(len(test_squad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "789\n",
      "846\n"
     ]
    }
   ],
   "source": [
    "print(len(train_wiki))\n",
    "print(len(val_wiki))\n",
    "print(len(test_wiki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wiki = train_wiki.sample(n=36000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the text into three parts\n",
    "def dep_split_text(text, prompt_length, answer_length):\n",
    "    words = text.split()\n",
    "    \n",
    "    first_batch = ' '.join(words[:prompt_length])\n",
    "    next_batch = ' '.join(words[prompt_length:prompt_length+answer_length])\n",
    "    \n",
    "    # The rest of the words\n",
    "    rest = ' '.join(words[prompt_length+answer_length:])\n",
    "    \n",
    "    return first_batch, next_batch, rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wiki[['prompt', 'answer']] = train_wiki['text'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)\n",
    "val_wiki[['prompt', 'answer']] = val_wiki['text'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)\n",
    "test_wiki[['prompt', 'answer']] = test_wiki['text'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad[['prompt', 'answer']] = train_squad['context'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)\n",
    "test_squad[['prompt', 'answer']] = test_squad['context'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)\n",
    "val_squad[['prompt', 'answer']] = val_squad['context'].apply(split_text, args=(prompt_length, answer_length)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wiki.to_csv(\"../data/wikitext/train.csv\", index=False) \n",
    "val_wiki.to_csv(\"../data/wikitext/val.csv\", index=False) \n",
    "test_wiki.to_csv(\"../data/wikitext/test.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad.to_csv(\"../data/squad/train.csv\", index=False) \n",
    "val_squad.to_csv(\"../data/squad/val.csv\", index=False)\n",
    "test_squad.to_csv(\"../data/squad/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vasilios",
   "language": "python",
   "name": "vasilios"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
